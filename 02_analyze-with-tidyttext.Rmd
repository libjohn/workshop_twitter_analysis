---
title: "Rtweet"
subtitle: "an Rfun demonstration"
author: "John Little"
date: '`r Sys.Date()`'
output: html_notebook
---

https://www.tidytextmining.com/

## load libraries

```{r libraries, message=FALSE, warning=FALSE}
library(rtweet)
library(tidyverse)
library(tidytext)
library(wordcloud2)
```




## Get Tweets 

search_tweets
```{r getTweets}
tweet_collection <- search_tweets("marchmadness", n=5000, lang = "en")

tweet_collection.orig <- tweet_collection
```


```{r process Tweets}
tweet_collection <- tweet_collection %>% 
  filter(is_retweet == "FALSE") %>% 
  filter(!str_detect(text, "electionnight")) %>% 
  filter(!str_detect(hashtags, "electionnight"))

tweet_collection
```


## Tokenize tweets

```{r corpus2vector}
tweets_by_tweeter <- tweet_collection %>% 
  group_by(screen_name) %>% 
  mutate(line = row_number()) %>% 
  ungroup()

tweets_by_tweeter %>% 
  count(screen_name, sort = TRUE)

# glimpse(tweets_by_tweeter)
```


> "Because we have kept text such as hashtags and usernames in the dataset, we canâ€™t use a simple anti_join() to remove stop words. Instead, we can take the approach shown in the filter() line that uses str_detect() from the stringr package. -- https://www.tidytextmining.com/twitter.html


```{r tokenized tweets}
tweets_tokenized <- tweets_by_tweeter %>% 
  select(text, screen_name, line) %>% 
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]")) 

tweets_tokenized
```

## stop words

```{r}
head(stopwordslangs)
```


```{r}
tweets_tokenized %>% 
  count(word, sort = TRUE, name = "freq") %>% 
  filter(!str_detect(word, "^\\@")) %>% 
  anti_join(stopwordslangs)           # anti_join(tidytext::get_stopwords())
```




## Word frequencies

### Calculate word frequency

```{r}
frequency <- tweets_tokenized %>% 
  group_by(screen_name) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tweets_tokenized %>% 
              group_by(screen_name) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)

frequency
```

> "This is a nice and tidy data frame but we would actually like to plot those frequencies on the x- and y-axes of a plot, so we will need to use spread() from tidyr make a differently shaped data frame. -- https://www.tidytextmining.com/twitter.html

pivot_wider

```{r}
frequency <- frequency %>% 
  select(screen_name, word, freq) %>% 
  pivot_wider(names_from = screen_name, values_from = freq) #, values_fill = 0)

frequency
```

### viz it

```{r word-cloud}
tweets_tokenized %>% 
  # group_by(screen_name) %>% 
  count(word, sort = TRUE, name = "freq") %>% 
  filter(!str_detect(word, "^\\@")) %>% 
  anti_join(stopwordslangs)  %>% 
  wordcloud2()

```
```{r word-freq barplot, fig.height=7}
tweets_tokenized %>% 
  count(word, sort = TRUE, name = "freq") %>% 
  filter(!str_detect(word, "^\\@")) %>% 
  slice_head(n = 30) %>% 
  ggplot(aes(freq, fct_reorder(word, freq))) +
  geom_col()

tweets_tokenized %>% 
  count(word, sort = TRUE, name = "freq") %>% 
  anti_join(stopwordslangs) %>% 
  filter(!str_detect(word, "^\\@")) %>% 
  slice_head(n = 30) %>% 
  ggplot(aes(freq, fct_reorder(word, freq))) +
  geom_col()
```


```{r word_freq plot}
ggplot(frequency, aes(CBBCent1, marchmadness)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = scales::percent_format()) +
  scale_y_log10(labels = scales::percent_format()) +
  geom_abline(color = "firebrick")

# fs::dir_create("images")
# ggsave("images/dukeball.png")

# "CBBCent1" | screen_name == "Adam_Bradford1
# marchmadness  TheAndyKatz

ggplot(frequency, aes(marchmadness, novainsider1985)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = scales::percent_format()) +
  scale_y_log10(labels = scales::percent_format()) +
  geom_abline(color = "firebrick")
```


## Word Usage


```{r}
tweets_by_tweeter %>% 
  summarise(min_date = min(created_at), max_date = max(created_at))
```


```{r}
word_ratios <- tweets_tokenized %>%
  # filter(screen_name == "CBBCent1" | screen_name == "Adam_Bradford14") %>%
  filter(screen_name == "LouInPain" | screen_name == "Dukeballnation") %>% 
  filter(!str_detect(word, "^@")) %>%
  count(word, screen_name) %>%
  group_by(word) %>%
  filter(sum(n) >= 2) %>%
  ungroup() %>%
  pivot_wider(names_from = screen_name, values_from = n, values_fill = 0) %>%
  mutate_if(is.numeric, list(~(. + 1) / (sum(.) + 1))) %>%
  mutate(logratio = log(LouInPain / Dukeballnation)) %>%
  arrange(desc(logratio))

word_ratios
```

### equal usage

```{r}
word_ratios %>% 
  arrange(abs(logratio))
```


```{r word-usage}
word_ratios %>%
  group_by(logratio < 0) %>%
  top_n(15, abs(logratio)) %>%
  ungroup() %>%
  mutate(word = reorder(word, logratio)) %>%
  ggplot(aes(word, logratio, fill = logratio < 0)) +
  geom_col() + #show.legend = FALSE) +
  coord_flip() +
  ylab("log odds ratio (CCBCent1/Adam_Bradford14)") +
  scale_fill_discrete(name = "", labels = c("LouInPain", "Dukeballnation"))
```


## Favorites and retweets

https://www.tidytextmining.com/twitter.html#favorites-and-retweets

## Changes in word use

https://www.tidytextmining.com/twitter.html#changes-in-word-use

## Term Document Matrix

```
{r}
# dtm <- DocumentTermMatrix(docs) 

dtm2 <- TermDocumentMatrix(corpus)
m <- as.matrix(dtm2)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

d <- d %>% 
  slice(2:200)

```

https://www.tidytextmining.com/tfidf.html#the-bind_tf_idf-function

```{r}
tweet_words <- tweets_by_tweeter %>% 
  select(screen_name, text, status_id, user_id) %>%  
  unnest_tokens(word, text, token = "tweets") %>% 
  filter(!str_detect(word, "^\\@")) %>%
  filter(!str_detect(word, "^http")) %>%
  anti_join(stopwordslangs)  %>% 
  count(word, tweeter = screen_name, sort = TRUE)

tweet_words

total_words <- tweet_words %>%
  group_by(tweeter) %>%
  summarize(total = sum(n)) %>% 
  arrange(-total)

total_words

tweet_words <- left_join(tweet_words, total_words)

tweet_words
```

```{r}
tweet_words %>% 
  bind_tf_idf(word, tweeter, n)
```

```{r fig.height=12}
tweet_words %>% 
  bind_tf_idf(word, tweeter, n) %>% 
  arrange(desc(tf_idf)) %>% 
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  filter(n > 2) %>% 
  # group_by(tweeter) %>% 
  # top_n(2) %>% 
  # ungroup() %>% 
  ggplot(aes(word, tf_idf)) +
  geom_col() +
  facet_wrap(~ tweeter) +
  coord_flip()
```





## Resource list

- http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know

- http://antonio-ferraro.eu.pn/word-clouds-in-r-packages-wordcloud2-and-tm/

- https://jrnold.github.io/qss-tidy/discovery.html#textual-data

- https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html

- of less use

    - http://www.cookbook-r.com/Manipulating_data/Converting_between_data_frames_and_contingency_tables/
    - https://www.r-bloggers.com/how-to-get-the-frequency-table-of-a-categorical-variable-as-a-data-frame-in-r/
    - https://www.quora.com/How-do-I-get-a-frequency-count-based-on-two-columns-variables-in-an-R-dataframe
    - https://www.quora.com/How-do-you-create-a-corpus-from-a-data-frame-in-R
    

